services:

  db:
    image: "postgres:16"
    platform: linux/amd64
    container_name: ops-db
    security_opt:
      - no-new-privileges:true  # Resolve semgrep https://sg.run/0n8q
    environment:
      - POSTGRES_PASSWORD=local_password
    read_only: true  # Resolve semgrep https://sg.run/e4JE
    tmpfs: /var/run/postgresql/
    volumes:
      - ./backend/data_tools/ops_db_sql_init:/docker-entrypoint-initdb.d
    ports:
      - "5432:5432"
    healthcheck:
      test: ["CMD-SHELL", "pg_isready -U postgres"]
      interval: 5s
      timeout: 5s
      retries: 5

  data-import:
    build:
      context: ./backend/
      dockerfile: Dockerfile.data-tools
    platform: linux/amd64
    container_name: ops-data-import
    environment:
      - ENV=local
      - SQLALCHEMY_DATABASE_URI=postgresql://ops:ops@db:5432/postgres
    command: >
      bash -c "
      psql postgresql://postgres:local_password@db:5432/postgres -c 'DROP SCHEMA IF EXISTS ops CASCADE;CREATE SCHEMA ops;GRANT ALL ON SCHEMA ops TO ops;' &&
      .local/bin/alembic upgrade head &&
      DATA=./data_tools/data/user_data.json5 python ./data_tools/src/import_static_data/import_data.py &&
      DATA=./data_tools/data/vendor_and_contact_data.json5 python ./data_tools/src/import_static_data/import_data.py &&
      DATA=./data_tools/data/portfolio_data.json5 python ./data_tools/src/import_static_data/import_data.py &&
      DATA=./data_tools/data/funding_partner_data.json5 python ./data_tools/src/import_static_data/import_data.py &&
      DATA=./data_tools/data/funding_source_data.json5 python ./data_tools/src/import_static_data/import_data.py &&
      DATA=./data_tools/data/research_project_data.json5 python ./data_tools/src/import_static_data/import_data.py &&
      DATA=./data_tools/data/can_data.json5 python ./data_tools/src/import_static_data/import_data.py &&
      DATA=./data_tools/data/first_contract_data.json5 python ./data_tools/src/import_static_data/import_data.py &&
      DATA=./data_tools/data/agreements_and_blin_data.json5 python ./data_tools/src/import_static_data/import_data.py &&
      DATA=./data_tools/data/workflow_data.json5 python ./data_tools/src/import_static_data/import_data.py
      "

    volumes:
      # See below for an explanation of this volume. The same reasoning applies,
      # but in this case it's so we can run new migrations immediately without
      # having to rebuild the migration container.
      - ./backend/ops_api:/home/app/ops_api
    depends_on:
      db:
        condition: service_healthy

  backend:
    build:
      context: ./backend/
      dockerfile: Dockerfile.ops-api
    platform: linux/amd64
    container_name: ops-backend
    ports:
      - "8080:8080"
    command: ["python", "-m", "flask", "run", "--debug", "--host=0.0.0.0", "--port=8080"]
    environment:
      - JWT_PRIVATE_KEY
      - JWT_PUBLIC_KEY
      - OPS_CONFIG=environment/local/container.py
    volumes:
      - ./backend/ops_api/ops:/home/app/ops_api/ops
    depends_on:
      db:
        condition: service_healthy
      data-import:
        condition: service_completed_successfully
    healthcheck:
      test: [ "CMD", "curl", "-f", "http://localhost:8080" ]
      interval: 10s
      timeout: 10s
      retries: 10

  frontend:
    build:
      context: ./frontend/
      dockerfile: Dockerfile
    platform: linux/amd64
    container_name: ops-frontend
    environment:
      - REACT_APP_BACKEND_DOMAIN=http://localhost:8080
      - VITE_BACKEND_DOMAIN=http://localhost:8080
    ports:
      - "3000:3000"
    depends_on:
      - backend
    volumes:
      - ./frontend/src:/home/app/src

  frontend-static:
    profiles: [static]
    build:
      context: ./frontend/
      dockerfile: Dockerfile.azure
      args:
        VITE_BACKEND_DOMAIN: http://localhost:8080
        MODE: dev  # set this to production to create a production build
    platform: linux/amd64
    container_name: ops-frontend-static
    ports:
      - "3000:3000"
    depends_on:
      - backend
    volumes:
      - ./frontend/src:/home/app/src
